#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„æŸå¤±å‡½æ•°
ä¸»è¦æ”¹è¿›ï¼š
1. è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
2. ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜
3. æ¨¡æ€å¯é æ€§åŠ æƒæŸå¤±
4. å¯¹æ¯”å­¦ä¹ å¢å¼º
"""

import torch
import torch.nn.functional as F
from torch import nn
from pytorch_metric_learning import losses, miners

try:
    from models import *
    from utils import *
except:
    from src.models import *
    from src.utils import *


class MsLoss(nn.Module):
    def __init__(self, device, thresh=0.5, scale_pos=0.1, scale_neg=40.0):
        super(MsLoss, self).__init__()
        self.device = device
        alpha, beta, base = scale_pos, scale_neg, thresh
        self.loss_func = losses.MultiSimilarityLoss(alpha=alpha, beta=beta, base=base)

    def sim(self, emb_left, emb_right):
        return emb_left.mm(emb_right.t())

    def forward(self, emb, train_links):
        emb = F.normalize(emb)
        emb_train_left = emb[train_links[:, 0]]
        emb_train_right = emb[train_links[:, 1]]
        labels = torch.arange(emb_train_left.size(0))
        embeddings = torch.cat([emb_train_left, emb_train_right], dim=0)
        labels = torch.cat([labels, labels], dim=0)
        loss = self.loss_func(embeddings, labels)
        return loss


class InfoNCE_loss(nn.Module):
    def __init__(self, device, temperature=0.05) -> None:
        super().__init__()
        self.device = device
        self.t = temperature
        self.ce_loss = nn.CrossEntropyLoss()

    def sim(self, emb_left, emb_right):
        return emb_left.mm(emb_right.t())

    def forward(self, emb, train_links):
        emb = F.normalize(emb)
        emb_train_left = emb[train_links[:, 0]]
        emb_train_right = emb[train_links[:, 1]]

        score = self.sim(emb_train_left, emb_train_right)
        bsize = emb_train_left.size()[0]
        label = torch.arange(bsize, dtype=torch.long).to(self.device)

        loss = self.ce_loss(score / self.t, label)
        return loss


class HardNegativeInfoNCE(nn.Module):
    """
    å¸¦ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜çš„InfoNCEæŸå¤±
    æ”¹è¿›ç‚¹ï¼šæ›´å…³æ³¨éš¾ä»¥åŒºåˆ†çš„è´Ÿæ ·æœ¬
    """
    
    def __init__(self, device, temperature=0.05, hard_negative_weight=0.5):
        super().__init__()
        self.device = device
        self.temperature = temperature
        self.hard_negative_weight = hard_negative_weight
        self.ce_loss = nn.CrossEntropyLoss()
    
    def forward(self, emb, train_links):
        emb = F.normalize(emb)
        emb_left = emb[train_links[:, 0]]
        emb_right = emb[train_links[:, 1]]
        
        batch_size = emb_left.size(0)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.mm(emb_left, emb_right.t()) / self.temperature
        
        # æ ‡å‡†InfoNCEæŸå¤±
        labels = torch.arange(batch_size, device=self.device)
        loss_l2r = self.ce_loss(sim_matrix, labels)
        loss_r2l = self.ce_loss(sim_matrix.t(), labels)
        standard_loss = (loss_l2r + loss_r2l) / 2
        
        # ç¡¬è´Ÿæ ·æœ¬æŸå¤±
        # æ‰¾åˆ°æ¯ä¸ªæ ·æœ¬æœ€éš¾çš„è´Ÿæ ·æœ¬ï¼ˆç›¸ä¼¼åº¦æœ€é«˜ä½†ä¸æ˜¯æ­£æ ·æœ¬çš„ï¼‰
        with torch.no_grad():
            # åˆ›å»ºmaskï¼Œæ’é™¤å¯¹è§’çº¿ï¼ˆæ­£æ ·æœ¬ï¼‰
            mask = torch.eye(batch_size, device=self.device).bool()
            sim_masked = sim_matrix.clone()
            sim_masked[mask] = -float('inf')
            
            # æ‰¾åˆ°æœ€éš¾çš„è´Ÿæ ·æœ¬
            hard_neg_indices = sim_masked.argmax(dim=1)
        
        # è®¡ç®—ç¡¬è´Ÿæ ·æœ¬çš„ä¸‰å…ƒç»„æŸå¤±
        hard_neg_emb = emb_right[hard_neg_indices]
        pos_sim = (emb_left * emb_right).sum(dim=1)
        neg_sim = (emb_left * hard_neg_emb).sum(dim=1)
        
        # margin-based triplet loss
        margin = 0.3
        triplet_loss = F.relu(neg_sim - pos_sim + margin).mean()
        
        total_loss = standard_loss + self.hard_negative_weight * triplet_loss
        
        return total_loss


class CrossModalConsistencyLoss(nn.Module):
    """
    è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
    å¼ºåˆ¶ä¸åŒæ¨¡æ€è¡¨ç¤ºåŒä¸€å®ä½“æ—¶ä¿æŒä¸€è‡´
    
    ä¿®å¤ï¼šå¤„ç†ä¸åŒæ¨¡æ€ç»´åº¦ä¸ä¸€è‡´çš„æƒ…å†µ
    """
    
    def __init__(self, device, temperature=0.1, consistency_weight=0.5):
        super().__init__()
        self.device = device
        self.temperature = temperature
        self.consistency_weight = consistency_weight
        self.projection_layers = nn.ModuleDict()  # åŠ¨æ€åˆ›å»ºæŠ•å½±å±‚
        self.standard_dim = 128  # æ ‡å‡†åŒ–ç»´åº¦
    
    def _get_projection(self, dim, name):
        """è·å–æˆ–åˆ›å»ºæŠ•å½±å±‚"""
        key = f"{name}_{dim}"
        if key not in self.projection_layers:
            self.projection_layers[key] = nn.Linear(dim, self.standard_dim).to(self.device)
        return self.projection_layers[key]
    
    def forward(self, modal_features, train_links):
        """
        è®¡ç®—è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
        
        Args:
            modal_features: dict, {modal_name: features [N, D]}
            train_links: è®­ç»ƒå¯¹é½é“¾æ¥ [M, 2]
        """
        # æ”¶é›†æœ‰æ•ˆæ¨¡æ€
        valid_modals = {k: v for k, v in modal_features.items() if v is not None}
        
        if len(valid_modals) < 2:
            return torch.tensor(0.0, device=self.device)
        
        total_loss = 0.0
        pair_count = 0
        
        modal_names = list(valid_modals.keys())
        
        # è®¡ç®—æ¯å¯¹æ¨¡æ€ä¹‹é—´çš„ä¸€è‡´æ€§æŸå¤±
        for i in range(len(modal_names)):
            for j in range(i + 1, len(modal_names)):
                modal_i = modal_names[i]
                modal_j = modal_names[j]
                
                try:
                    feat_i = valid_modals[modal_i]
                    feat_j = valid_modals[modal_j]
                    
                    # ğŸ”§ ä¿®å¤ï¼šæŠ•å½±åˆ°ç›¸åŒç»´åº¦
                    if feat_i.size(-1) != self.standard_dim:
                        proj_i = self._get_projection(feat_i.size(-1), modal_i)
                        feat_i = proj_i(feat_i)
                    if feat_j.size(-1) != self.standard_dim:
                        proj_j = self._get_projection(feat_j.size(-1), modal_j)
                        feat_j = proj_j(feat_j)
                    
                    feat_i = F.normalize(feat_i, dim=-1)
                    feat_j = F.normalize(feat_j, dim=-1)
                    
                    # ç¡®ä¿batch sizeä¸€è‡´
                    min_size = min(feat_i.size(0), feat_j.size(0))
                    feat_i = feat_i[:min_size]
                    feat_j = feat_j[:min_size]
                    
                    # è¿‡æ»¤æœ‰æ•ˆçš„è®­ç»ƒé“¾æ¥
                    valid_links = train_links[train_links[:, 0] < min_size]
                    valid_links = valid_links[valid_links[:, 1] < min_size]
                    
                    if len(valid_links) == 0:
                        continue
                    
                    # è·å–å¯¹é½å®ä½“çš„ç‰¹å¾
                    aligned_i = feat_i[valid_links[:, 0]]
                    aligned_j = feat_j[valid_links[:, 1]]
                    
                    # è®¡ç®—å¯¹æ¯”æŸå¤±ï¼ˆç°åœ¨ç»´åº¦ä¸€è‡´äº†ï¼‰
                    sim_matrix = torch.mm(aligned_i, aligned_j.t()) / self.temperature
                    batch_size = sim_matrix.size(0)
                    labels = torch.arange(batch_size, device=self.device)
                    
                    loss_ij = F.cross_entropy(sim_matrix, labels)
                    loss_ji = F.cross_entropy(sim_matrix.t(), labels)
                    
                    total_loss += (loss_ij + loss_ji) / 2
                    pair_count += 1
                    
                except Exception as e:
                    # è·³è¿‡å‡ºé”™çš„æ¨¡æ€å¯¹
                    continue
        
        if pair_count > 0:
            return self.consistency_weight * total_loss / pair_count
        else:
            return torch.tensor(0.0, device=self.device)


class ModalityReliabilityWeightedLoss(nn.Module):
    """
    åŸºäºæ¨¡æ€å¯é æ€§çš„åŠ æƒæŸå¤±
    å¯¹äºä½è´¨é‡/ç¼ºå¤±æ¨¡æ€ï¼Œé™ä½å…¶åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡
    """
    
    def __init__(self, device, base_temperature=0.05):
        super().__init__()
        self.device = device
        self.base_temperature = base_temperature
        self.ce_loss = nn.CrossEntropyLoss(reduction='none')
    
    def compute_reliability_scores(self, features, reference_features=None):
        """
        è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¯é æ€§åˆ†æ•°
        åŸºäºç‰¹å¾æ–¹å·®å’Œä¸å‚è€ƒç‰¹å¾çš„ä¸€è‡´æ€§
        """
        if features is None:
            return None
        
        # è®¡ç®—ç‰¹å¾æ–¹å·®ï¼ˆä½æ–¹å·®å¯èƒ½è¡¨ç¤ºéšæœºå¡«å……ï¼‰
        feature_var = features.var(dim=-1)
        var_score = torch.sigmoid(feature_var * 10 - 0.5)
        
        # è®¡ç®—ç‰¹å¾èŒƒæ•°
        feature_norm = features.norm(dim=-1)
        norm_score = torch.sigmoid(feature_norm - 0.5)
        
        # å¦‚æœæœ‰å‚è€ƒç‰¹å¾ï¼Œè®¡ç®—ä¸€è‡´æ€§
        if reference_features is not None:
            ref_norm = F.normalize(reference_features, dim=-1)
            feat_norm = F.normalize(features, dim=-1)
            consistency = (ref_norm * feat_norm).sum(dim=-1)
            consistency_score = (consistency + 1) / 2  # å½’ä¸€åŒ–åˆ°[0, 1]
            reliability = (var_score + norm_score + consistency_score) / 3
        else:
            reliability = (var_score + norm_score) / 2
        
        return reliability
    
    def forward(self, emb, train_links, reliability_scores=None):
        """
        åŠ æƒInfoNCEæŸå¤±
        """
        emb = F.normalize(emb)
        emb_left = emb[train_links[:, 0]]
        emb_right = emb[train_links[:, 1]]
        
        batch_size = emb_left.size(0)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.mm(emb_left, emb_right.t()) / self.base_temperature
        
        labels = torch.arange(batch_size, device=self.device)
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æŸå¤±
        loss_per_sample = self.ce_loss(sim_matrix, labels)
        
        # å¦‚æœæœ‰å¯é æ€§åˆ†æ•°ï¼Œè¿›è¡ŒåŠ æƒ
        if reliability_scores is not None:
            # è·å–è®­ç»ƒæ ·æœ¬çš„å¯é æ€§åˆ†æ•°
            rel_left = reliability_scores[train_links[:, 0]]
            rel_right = reliability_scores[train_links[:, 1]]
            sample_weights = (rel_left + rel_right) / 2
            
            # å½’ä¸€åŒ–æƒé‡
            sample_weights = sample_weights / (sample_weights.sum() + 1e-8) * batch_size
            
            weighted_loss = (loss_per_sample * sample_weights).mean()
        else:
            weighted_loss = loss_per_sample.mean()
        
        return weighted_loss


class CLIPAlignmentLoss(nn.Module):
    """ä¿®æ­£çš„CLIPå¯¹é½æŸå¤±å‡½æ•°"""
    
    def __init__(self, device, temperature=0.07):
        super(CLIPAlignmentLoss, self).__init__()
        self.device = device
        self.temperature = temperature
        self.ce_loss = nn.CrossEntropyLoss()
    
    def forward(self, clip_features, train_links):
        """
        è®¡ç®—CLIPé£æ ¼çš„å¯¹æ¯”å­¦ä¹ æŸå¤±
        """
        if not isinstance(clip_features, dict):
            return torch.tensor(0.0, device=self.device)
            
        if 'image_embeds' not in clip_features or 'text_embeds' not in clip_features:
            return torch.tensor(0.0, device=self.device)
        
        img_embeds = clip_features['image_embeds']
        text_embeds = clip_features['text_embeds']
        
        if img_embeds is None or text_embeds is None:
            return torch.tensor(0.0, device=self.device)
        
        img_embeds = img_embeds.to(self.device)
        text_embeds = text_embeds.to(self.device)
        
        img_embeds = F.normalize(img_embeds, dim=-1)
        text_embeds = F.normalize(text_embeds, dim=-1)
        
        min_batch_size = min(img_embeds.size(0), text_embeds.size(0))
        img_embeds = img_embeds[:min_batch_size]
        text_embeds = text_embeds[:min_batch_size]
        
        batch_size = img_embeds.size(0)
        
        if batch_size == 0:
            return torch.tensor(0.0, device=self.device)
        
        sim_i2t = torch.matmul(img_embeds, text_embeds.T) / self.temperature
        sim_t2i = torch.matmul(text_embeds, img_embeds.T) / self.temperature
        
        labels = torch.arange(batch_size, device=self.device)
        
        loss_i2t = self.ce_loss(sim_i2t, labels)
        loss_t2i = self.ce_loss(sim_t2i, labels)
        
        return (loss_i2t + loss_t2i) / 2


class CrossModalAlignmentLoss(nn.Module):
    """è·¨æ¨¡æ€å¯¹é½æŸå¤±ï¼Œç”¨äºentity alignmentä»»åŠ¡"""
    
    def __init__(self, device, temperature=0.07, margin=0.1):
        super(CrossModalAlignmentLoss, self).__init__()
        self.device = device
        self.temperature = temperature
        self.margin = margin
        self.ce_loss = nn.CrossEntropyLoss()
    
    def forward(self, embeddings, train_links, modal_features=None):
        """
        è·¨æ¨¡æ€å¯¹é½æŸå¤±
        """
        if embeddings is None:
            return torch.tensor(0.0, device=self.device)
        
        try:
            total_loss = 0.0
            loss_count = 0
            
            # 1. ä¸»è¦çš„å®ä½“å¯¹é½æŸå¤±
            embeddings = F.normalize(embeddings, dim=-1)
            left_embeds = embeddings[train_links[:, 0]]
            right_embeds = embeddings[train_links[:, 1]]
            
            sim_matrix = torch.matmul(left_embeds, right_embeds.T) / self.temperature
            batch_size = sim_matrix.size(0)
            labels = torch.arange(batch_size, device=self.device)
            
            loss_l2r = self.ce_loss(sim_matrix, labels)
            loss_r2l = self.ce_loss(sim_matrix.T, labels)
            
            alignment_loss = (loss_l2r + loss_r2l) / 2
            total_loss += alignment_loss
            loss_count += 1
            
            # 2. è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
            if modal_features is not None and isinstance(modal_features, dict):
                modal_consistency_loss = 0.0
                modal_count = 0
                
                valid_modals = {k: v for k, v in modal_features.items() 
                              if v is not None and k != 'clip'}
                
                modal_list = list(valid_modals.values())
                
                for i in range(len(modal_list)):
                    for j in range(i + 1, len(modal_list)):
                        try:
                            feat_i = F.normalize(modal_list[i], dim=-1)
                            feat_j = F.normalize(modal_list[j], dim=-1)
                            
                            min_size = min(feat_i.size(0), feat_j.size(0))
                            feat_i = feat_i[:min_size]
                            feat_j = feat_j[:min_size]
                            
                            valid_train_links = train_links[train_links[:, 0] < min_size]
                            valid_train_links = valid_train_links[valid_train_links[:, 1] < min_size]
                            
                            if len(valid_train_links) == 0:
                                continue
                            
                            feat_i_aligned = feat_i[valid_train_links[:, 0]]
                            feat_j_aligned = feat_j[valid_train_links[:, 1]]
                            
                            cosine_sim = F.cosine_similarity(feat_i_aligned, feat_j_aligned, dim=-1)
                            consistency_loss = 1.0 - cosine_sim.mean()
                            
                            modal_consistency_loss += consistency_loss
                            modal_count += 1
                            
                        except Exception as e:
                            continue
                
                if modal_count > 0:
                    total_loss += 0.1 * modal_consistency_loss / modal_count
            
            return total_loss
            
        except Exception as e:
            return torch.tensor(0.0, device=self.device)


class CLIPAwareContrastiveLoss(nn.Module):
    """CLIPæ„ŸçŸ¥çš„å¯¹æ¯”å­¦ä¹ æŸå¤±"""
    
    def __init__(self, device, temperature=0.07, clip_weight=0.1, entity_weight=1.0):
        super(CLIPAwareContrastiveLoss, self).__init__()
        self.device = device
        self.clip_loss = CLIPAlignmentLoss(device, temperature)
        self.alignment_loss = CrossModalAlignmentLoss(device, temperature)
        self.clip_weight = clip_weight
        self.entity_weight = entity_weight
    
    def forward(self, joint_embeddings, train_links, clip_features=None, modal_features=None):
        """
        è®¡ç®—ç»¼åˆæŸå¤±
        """
        total_loss = torch.tensor(0.0, device=self.device)
        
        try:
            if joint_embeddings is not None:
                entity_loss = self.alignment_loss(joint_embeddings, train_links, modal_features)
                total_loss += self.entity_weight * entity_loss
            
            if clip_features is not None and self.clip_weight > 0:
                clip_loss = self.clip_loss(clip_features, train_links)
                total_loss += self.clip_weight * clip_loss
            
            return total_loss
            
        except Exception as e:
            return torch.tensor(0.0, device=self.device)


class VIBLoss(nn.Module):
    """å˜åˆ†ä¿¡æ¯ç“¶é¢ˆæŸå¤±"""
    
    def __init__(self, device, beta=0.001):
        super(VIBLoss, self).__init__()
        self.device = device
        self.beta = beta
    
    def forward(self, kld_losses):
        """è®¡ç®—VIBæŸå¤±"""
        try:
            total_kld = 0.0
            count = 0
            
            for modal_name, kld_loss in kld_losses.items():
                if kld_loss > 0:
                    total_kld += kld_loss
                    count += 1
            
            if count > 0:
                return self.beta * (total_kld / count)
            else:
                return torch.tensor(0.0, device=self.device)
                
        except Exception as e:
            return torch.tensor(0.0, device=self.device)


class AdaptiveLossWeighting(nn.Module):
    """è‡ªé€‚åº”æŸå¤±æƒé‡è°ƒæ•´"""
    
    def __init__(self, num_losses, device):
        super(AdaptiveLossWeighting, self).__init__()
        self.device = device
        self.num_losses = num_losses
        self.log_vars = nn.Parameter(torch.zeros(num_losses))
    
    def forward(self, losses):
        """è®¡ç®—åŠ æƒæŸå¤±"""
        try:
            if len(losses) != self.num_losses:
                return sum(losses) / max(len(losses), 1)
            
            weighted_losses = []
            for i, loss in enumerate(losses):
                precision = torch.exp(-self.log_vars[i])
                weighted_loss = precision * loss + self.log_vars[i]
                weighted_losses.append(weighted_loss)
            
            return sum(weighted_losses)
            
        except Exception as e:
            return sum(losses) / max(len(losses), 1)


class ImprovedComprehensiveLoss(nn.Module):
    """
    æ”¹è¿›çš„ç»¼åˆæŸå¤±å‡½æ•°
    ä¸»è¦æ”¹è¿›ï¼š
    1. ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜
    2. è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
    3. æ¨¡æ€å¯é æ€§åŠ æƒ
    """
    
    def __init__(self, args, device):
        super(ImprovedComprehensiveLoss, self).__init__()
        self.args = args
        self.device = device
        
        # åŸºç¡€æŸå¤±å‡½æ•° - ä½¿ç”¨æ”¹è¿›ç‰ˆæœ¬
        self.hard_nce = HardNegativeInfoNCE(
            device, 
            temperature=args.tau,
            hard_negative_weight=getattr(args, 'hard_negative_weight', 0.5)
        )
        self.ms_loss = MsLoss(
            device, 
            thresh=getattr(args, 'ms_base', 0.5),
            scale_pos=getattr(args, 'ms_alpha', 0.1), 
            scale_neg=getattr(args, 'ms_beta', 40.0)
        )
        
        # è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±
        self.cross_modal_loss = CrossModalConsistencyLoss(
            device,
            temperature=0.1,
            consistency_weight=getattr(args, 'cross_modal_weight', 0.3)
        )
        
        # æ¨¡æ€å¯é æ€§åŠ æƒæŸå¤±
        self.reliability_weighted_loss = ModalityReliabilityWeightedLoss(
            device,
            base_temperature=args.tau
        )
        
        # CLIPç›¸å…³æŸå¤±
        if getattr(args, 'use_clip', False):
            self.clip_loss = CLIPAwareContrastiveLoss(
                device=device,
                temperature=getattr(args, 'clip_temperature', 0.07),
                clip_weight=getattr(args, 'clip_weight', 0.1),
                entity_weight=1.0
            )
        
        # VIBæŸå¤±
        self.vib_loss = VIBLoss(device, beta=0.001)
        
        # è‡ªé€‚åº”æƒé‡
        self.use_adaptive_weighting = getattr(args, 'use_adaptive_weighting', False)
        if self.use_adaptive_weighting:
            num_losses = 0
            if args.w_gcn: num_losses += 1
            if args.w_img: num_losses += 1
            if args.w_rel: num_losses += 1
            if args.w_attr: num_losses += 1
            if getattr(args, 'use_clip', False): num_losses += 1
            num_losses += 2  # joint loss + cross modal loss
            
            self.adaptive_weighting = AdaptiveLossWeighting(num_losses, device)
    
    def forward(self, embeddings_dict, train_links, model):
        """
        è®¡ç®—ç»¼åˆæŸå¤±
        """
        try:
            total_loss = 0.0
            loss_components = {}
            individual_losses = []
            
            # 1. å„æ¨¡æ€çš„æŸå¤±ï¼ˆä½¿ç”¨ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ï¼‰
            if self.args.w_gcn and 'graph' in embeddings_dict and embeddings_dict['graph'] is not None:
                gph_loss = self.hard_nce(embeddings_dict['graph'], train_links)
                if hasattr(model, 'kld_loss') and model.kld_loss > 0:
                    gph_loss += self.args.Beta_g * model.kld_loss
                loss_components['graph'] = gph_loss
                individual_losses.append(gph_loss)
            
            if self.args.w_img and 'image' in embeddings_dict and embeddings_dict['image'] is not None:
                img_loss = self.hard_nce(embeddings_dict['image'], train_links)
                if hasattr(model, 'img_kld_loss') and model.img_kld_loss > 0:
                    img_loss += self.args.Beta_i * model.img_kld_loss
                loss_components['image'] = img_loss
                individual_losses.append(img_loss)
            
            if self.args.w_rel and 'relation' in embeddings_dict and embeddings_dict['relation'] is not None:
                rel_loss = self.hard_nce(embeddings_dict['relation'], train_links)
                if hasattr(model, 'rel_kld_loss') and model.rel_kld_loss > 0:
                    rel_loss += self.args.Beta_r * model.rel_kld_loss
                loss_components['relation'] = rel_loss
                individual_losses.append(rel_loss)
            
            if self.args.w_attr and 'attribute' in embeddings_dict and embeddings_dict['attribute'] is not None:
                attr_loss = self.hard_nce(embeddings_dict['attribute'], train_links)
                if hasattr(model, 'attr_kld_loss') and model.attr_kld_loss > 0:
                    attr_loss += self.args.Beta_a * model.attr_kld_loss
                loss_components['attribute'] = attr_loss
                individual_losses.append(attr_loss)
            
            # 2. CLIPæŸå¤±
            if getattr(self.args, 'use_clip', False) and hasattr(model, 'clip_features'):
                clip_loss = self.clip_loss(
                    embeddings_dict.get('joint', None),
                    train_links,
                    model.clip_features,
                    embeddings_dict
                )
                loss_components['clip'] = clip_loss
                individual_losses.append(clip_loss)
            
            # 3. è”åˆæŸå¤±
            if 'joint' in embeddings_dict and embeddings_dict['joint'] is not None:
                if getattr(self.args, 'use_joint_vib', False):
                    joint_loss = self.hard_nce(embeddings_dict['joint'], train_links)
                    if hasattr(model, 'joint_kld_loss') and model.joint_kld_loss > 0:
                        joint_loss += getattr(self.args, 'joint_beta', 1.0) * model.joint_kld_loss
                else:
                    joint_loss = self.ms_loss(embeddings_dict['joint'], train_links)
                    joint_loss *= getattr(self.args, 'joint_beta', 1.0)
                
                loss_components['joint'] = joint_loss
                individual_losses.append(joint_loss)
            
            # 4. è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±ï¼ˆæ–°å¢ï¼ï¼‰
            if hasattr(model, 'modal_features') and model.modal_features:
                cross_modal_loss = self.cross_modal_loss(model.modal_features, train_links)
                loss_components['cross_modal'] = cross_modal_loss
                individual_losses.append(cross_modal_loss)
            
            # 5. è·¨æ¨¡æ€å¯¹é½æŸå¤±ï¼ˆä»æ¨¡å‹è·å–ï¼‰
            if hasattr(model, 'get_cross_modal_alignment_loss'):
                alignment_loss = model.get_cross_modal_alignment_loss(train_links)
                if alignment_loss > 0:
                    loss_components['alignment'] = alignment_loss
                    individual_losses.append(0.2 * alignment_loss)
            
            # 6. ç»„åˆæŸå¤±
            if self.use_adaptive_weighting and len(individual_losses) > 1:
                total_loss = self.adaptive_weighting(individual_losses)
            else:
                total_loss = sum(individual_losses) if individual_losses else torch.tensor(0.0, device=self.device)
            
            return total_loss, loss_components
            
        except Exception as e:
            print(f"Loss computation error: {e}")
            return torch.tensor(0.0, device=self.device), {}


# ä¿æŒå‘åå…¼å®¹
ComprehensiveLoss = ImprovedComprehensiveLoss